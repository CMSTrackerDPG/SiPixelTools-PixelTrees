[CRAB]

jobtype = cmssw
##### FOR ALL
scheduler = glitecoll
##### FOR CAF
#scheduler = caf 


[CMSSW]

### The data you want to access (to be found on DBS) 
#datasetpath=/MinimumBias/BeamCommissioning09-PromptReco-v2/RECO
datasetpath=/MinBias/Summer09-D6T_STARTUP3X_V8I_900GeV-v1/GEN-SIM-RAW 
#datasetpath=/ExpressPhysics/BeamCommissioning09-Express-v2/FEVT
#datasetpath=/MinimumBias/BeamCommissioning09-SD_InterestingEvents_MinBias10-PromptSkimCommissioning_v1/FEVT

##### FOR CAF
#dbs_url=http://cmsdbsprod.cern.ch/cms_dbs_caf_analysis_01/servlet/DBSServlet

### The ParameterSet you want to use
pset=DIRECTORY/pixelefficiency_cfg1.py

### Splitting parameters
total_number_of_events=5000
events_per_job = 500
#number_of_jobs = 1

### The output files (comma separated list)
output_file = pixelEfficiency1.root

#runselection=123151

[USER]

### OUTPUT files Management
##  output back into UI 
return_data = 1
### If return_data = 1 ###
## UI directory where to store the stderr, stdout and .BrokerInfo of submitted jobs
## FULL path is mandatory. If none <ui_working_dir>/res will be used.
#logdir=/afs/cern.ch/user/p/pkreuzer/scratch0/res/
# UI directory where to store the CMS executable output
## FULL path is mandatory. If none <ui_working_dir>/res will be used.
#outputdir=DIRECTORY

### OUTPUT files INTO A SE
copy_data = 0
#storage_element = srm.cern.ch
#storage_path = /castor/cern.ch/cms/store/cmscaf/physics/data/SUSYBSMJetMet_HLT/Gumbo100pb/
#/castor/cern.ch/cms/store/cmscaf/physics/data/SUSYBSMJetMet_HLT/Gumbo/

#if server mode = 1 
#eMail = your@Email.address 

[GRID]
virtual_organization    = cms
group                   = becms

[EDG]

## RB/WMS management:
#rb = CNAF

##  Black and White Lists management:
## By Storage
se_black_list = ce01.lcg.cscs.ch
#se_white_list = cmssrm.fnal.gov

## By ComputingElement 
ce_black_list = ce01.lcg.cscs.ch
#ce_white_list = cern

[CONDORG]

# Set this to condor to override the batchsystem defined in gridcat.
#batchsystem = condor

# Specify addition condor_g requirments
# use this requirment to run on a cms dedicated hardare
# globus_rsl = (condor_submit=(requirements 'ClusterName == \"CMS\" && (Arch == \"INTEL\" || Arch == \"X86_64\")'))
# use this requirement to run on the new hardware
#globus_rsl = (condor_submit=(requirements 'regexp(\"cms-*\",Machine)'))

